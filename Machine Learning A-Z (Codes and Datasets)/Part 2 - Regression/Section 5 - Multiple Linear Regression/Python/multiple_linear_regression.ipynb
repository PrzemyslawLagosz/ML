{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CazISR8X_HUG"},"source":["# Multiple Linear Regression"]},{"cell_type":"markdown","metadata":{},"source":["## In Multiple Linear Regression there is `NO NEED` to apply feature scaling\n","## `from sklearn.linear_model import LinearRegression` CAN handle one extradummy variable\n","\n","* Podział na zmienne zalezne i niezależne\n","* Encoding danych categorical\n","* Split set\n","* Train Multiple Linear Redression model\n","* `backward elimination` with ststsmodel.api module\n","* Ocena modelu `from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pOyqYHTk_Q57"},"source":["## Importing the libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{},"colab_type":"code","id":"T_YHJjnD_Tja"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vgC61-ah_WIz"},"source":["## Importing the dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{},"colab_type":"code","id":"UrxyEKGn_ez7"},"outputs":[],"source":["dataset = pd.read_csv('50_Startups.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>R&amp;D Spend</th>\n","      <th>Administration</th>\n","      <th>Marketing Spend</th>\n","      <th>State</th>\n","      <th>Profit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>165349.20</td>\n","      <td>136897.80</td>\n","      <td>471784.10</td>\n","      <td>New York</td>\n","      <td>192261.83</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>162597.70</td>\n","      <td>151377.59</td>\n","      <td>443898.53</td>\n","      <td>California</td>\n","      <td>191792.06</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>153441.51</td>\n","      <td>101145.55</td>\n","      <td>407934.54</td>\n","      <td>Florida</td>\n","      <td>191050.39</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>144372.41</td>\n","      <td>118671.85</td>\n","      <td>383199.62</td>\n","      <td>New York</td>\n","      <td>182901.99</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>142107.34</td>\n","      <td>91391.77</td>\n","      <td>366168.42</td>\n","      <td>Florida</td>\n","      <td>166187.94</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   R&D Spend  Administration  Marketing Spend       State     Profit\n","0  165349.20       136897.80        471784.10    New York  192261.83\n","1  162597.70       151377.59        443898.53  California  191792.06\n","2  153441.51       101145.55        407934.54     Florida  191050.39\n","3  144372.41       118671.85        383199.62    New York  182901.99\n","4  142107.34        91391.77        366168.42     Florida  166187.94"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["dataset.head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 50 entries, 0 to 49\n","Data columns (total 5 columns):\n"," #   Column           Non-Null Count  Dtype  \n","---  ------           --------------  -----  \n"," 0   R&D Spend        50 non-null     float64\n"," 1   Administration   50 non-null     float64\n"," 2   Marketing Spend  50 non-null     float64\n"," 3   State            50 non-null     object \n"," 4   Profit           50 non-null     float64\n","dtypes: float64(4), object(1)\n","memory usage: 2.1+ KB\n"]}],"source":["dataset.info()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>R&amp;D Spend</th>\n","      <th>Administration</th>\n","      <th>Marketing Spend</th>\n","      <th>Profit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>50.000000</td>\n","      <td>50.000000</td>\n","      <td>50.000000</td>\n","      <td>50.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>73721.615600</td>\n","      <td>121344.639600</td>\n","      <td>211025.097800</td>\n","      <td>112012.639200</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>45902.256482</td>\n","      <td>28017.802755</td>\n","      <td>122290.310726</td>\n","      <td>40306.180338</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>51283.140000</td>\n","      <td>0.000000</td>\n","      <td>14681.400000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>39936.370000</td>\n","      <td>103730.875000</td>\n","      <td>129300.132500</td>\n","      <td>90138.902500</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>73051.080000</td>\n","      <td>122699.795000</td>\n","      <td>212716.240000</td>\n","      <td>107978.190000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>101602.800000</td>\n","      <td>144842.180000</td>\n","      <td>299469.085000</td>\n","      <td>139765.977500</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>165349.200000</td>\n","      <td>182645.560000</td>\n","      <td>471784.100000</td>\n","      <td>192261.830000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           R&D Spend  Administration  Marketing Spend         Profit\n","count      50.000000       50.000000        50.000000      50.000000\n","mean    73721.615600   121344.639600    211025.097800  112012.639200\n","std     45902.256482    28017.802755    122290.310726   40306.180338\n","min         0.000000    51283.140000         0.000000   14681.400000\n","25%     39936.370000   103730.875000    129300.132500   90138.902500\n","50%     73051.080000   122699.795000    212716.240000  107978.190000\n","75%    101602.800000   144842.180000    299469.085000  139765.977500\n","max    165349.200000   182645.560000    471784.100000  192261.830000"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dataset.describe()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["array([[165349.2, 136897.8, 471784.1, 'New York'],\n","       [162597.7, 151377.59, 443898.53, 'California'],\n","       [153441.51, 101145.55, 407934.54, 'Florida'],\n","       [144372.41, 118671.85, 383199.62, 'New York'],\n","       [142107.34, 91391.77, 366168.42, 'Florida'],\n","       [131876.9, 99814.71, 362861.36, 'New York'],\n","       [134615.46, 147198.87, 127716.82, 'California'],\n","       [130298.13, 145530.06, 323876.68, 'Florida'],\n","       [120542.52, 148718.95, 311613.29, 'New York'],\n","       [123334.88, 108679.17, 304981.62, 'California'],\n","       [101913.08, 110594.11, 229160.95, 'Florida'],\n","       [100671.96, 91790.61, 249744.55, 'California'],\n","       [93863.75, 127320.38, 249839.44, 'Florida'],\n","       [91992.39, 135495.07, 252664.93, 'California'],\n","       [119943.24, 156547.42, 256512.92, 'Florida'],\n","       [114523.61, 122616.84, 261776.23, 'New York'],\n","       [78013.11, 121597.55, 264346.06, 'California'],\n","       [94657.16, 145077.58, 282574.31, 'New York'],\n","       [91749.16, 114175.79, 294919.57, 'Florida'],\n","       [86419.7, 153514.11, 0.0, 'New York'],\n","       [76253.86, 113867.3, 298664.47, 'California'],\n","       [78389.47, 153773.43, 299737.29, 'New York'],\n","       [73994.56, 122782.75, 303319.26, 'Florida'],\n","       [67532.53, 105751.03, 304768.73, 'Florida'],\n","       [77044.01, 99281.34, 140574.81, 'New York'],\n","       [64664.71, 139553.16, 137962.62, 'California'],\n","       [75328.87, 144135.98, 134050.07, 'Florida'],\n","       [72107.6, 127864.55, 353183.81, 'New York'],\n","       [66051.52, 182645.56, 118148.2, 'Florida'],\n","       [65605.48, 153032.06, 107138.38, 'New York'],\n","       [61994.48, 115641.28, 91131.24, 'Florida'],\n","       [61136.38, 152701.92, 88218.23, 'New York'],\n","       [63408.86, 129219.61, 46085.25, 'California'],\n","       [55493.95, 103057.49, 214634.81, 'Florida'],\n","       [46426.07, 157693.92, 210797.67, 'California'],\n","       [46014.02, 85047.44, 205517.64, 'New York'],\n","       [28663.76, 127056.21, 201126.82, 'Florida'],\n","       [44069.95, 51283.14, 197029.42, 'California'],\n","       [20229.59, 65947.93, 185265.1, 'New York'],\n","       [38558.51, 82982.09, 174999.3, 'California'],\n","       [28754.33, 118546.05, 172795.67, 'California'],\n","       [27892.92, 84710.77, 164470.71, 'Florida'],\n","       [23640.93, 96189.63, 148001.11, 'California'],\n","       [15505.73, 127382.3, 35534.17, 'New York'],\n","       [22177.74, 154806.14, 28334.72, 'California'],\n","       [1000.23, 124153.04, 1903.93, 'New York'],\n","       [1315.46, 115816.21, 297114.46, 'Florida'],\n","       [0.0, 135426.92, 0.0, 'California'],\n","       [542.05, 51743.15, 0.0, 'New York'],\n","       [0.0, 116983.8, 45173.06, 'California']], dtype=object)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["X\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VadrvE7s_lS9"},"source":["## Encoding categorical data"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer"]},{"cell_type":"markdown","metadata":{},"source":["# OneHotEncoder(`drop= \"first\"`) to drop one dummy variable"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ct = ColumnTransformer(transformers=[(\"encoder\", OneHotEncoder(), [3])], remainder= \"passthrough\")\n","X = ct.fit_transform(X)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n","       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n","       [0.0, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n","       [0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n","       [0.0, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n","       [0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n","       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n","       [0.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n","       [0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n","       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n","       [0.0, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n","       [1.0, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n","       [0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n","       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n","       [0.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n","       [0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n","       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n","       [0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n","       [0.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n","       [0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n","       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n","       [0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n","       [0.0, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n","       [0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n","       [0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n","       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n","       [0.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n","       [0.0, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n","       [0.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n","       [0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n","       [0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n","       [0.0, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n","       [1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n","       [0.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n","       [1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n","       [0.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n","       [0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n","       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n","       [0.0, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n","       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n","       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n","       [0.0, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n","       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n","       [0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n","       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n","       [0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n","       [0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n","       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n","       [0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n","       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["X"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WemVnqgeA70k"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 0)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k-McZVsQBINc"},"source":["## Training the Multiple Linear Regression model on the Training set"]},{"cell_type":"markdown","metadata":{},"source":["### This Class of ML Model automatically `handle Dummy Variable Trap~`! also there is no need of `backward elimination`, it doing this automatically  "]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n","       [0.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n","       [0.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n","       [1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n","       [0.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n","       [0.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n","       [0.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n","       [0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n","       [0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n","       [0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n","       [0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n","       [0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n","       [1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n","       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n","       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n","       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n","       [0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n","       [0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n","       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n","       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n","       [0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n","       [0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n","       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n","       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06],\n","       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n","       [0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n","       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n","       [0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n","       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n","       [0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n","       [0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n","       [0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n","       [0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n","       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n","       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n","       [0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n","       [0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n","       [0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n","       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n","       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72]], dtype=object)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["X_train"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"],"text/plain":["LinearRegression()"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["regressor = LinearRegression()\n","regressor.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 8.66383692e+01 -8.72645791e+02  7.86007422e+02  7.73467193e-01\n","  3.28845975e-02  3.66100259e-02]\n","42467.52924853325\n"]}],"source":["print(regressor.coef_)\n","print(regressor.intercept_)"]},{"cell_type":"markdown","metadata":{},"source":["Profit=86.6×Dummy State 1−873×Dummy State 2+786×Dummy State 3+0.773×R&D Spend+0.0329×Administration+0.0366×Marketing Spend+42467.53"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["0.93470684732822"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["regressor.score(X_test, y_test)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xNkXL1YQBiBT"},"source":["## Predicting the Test set results"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["array([103015.20159796, 132582.27760815, 132447.73845175,  71976.09851258,\n","       178537.48221056, 116161.24230167,  67851.69209676,  98791.73374687,\n","       113969.43533013, 167921.06569551])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = regressor.predict(X_test)\n","y_pred"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["array([103015.2 , 132582.28, 132447.74,  71976.1 , 178537.48, 116161.24,\n","        67851.69,  98791.73, 113969.44, 167921.07])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["np.round(y_pred, 2)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["np.set_printoptions(precision= 2)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>y_test</th>\n","      <th>y_pred</th>\n","      <th>AE</th>\n","      <th>RE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>103282.38</td>\n","      <td>103015.20</td>\n","      <td>-267.18</td>\n","      <td>-0.26</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>144259.40</td>\n","      <td>132582.28</td>\n","      <td>-11677.12</td>\n","      <td>-8.09</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>146121.95</td>\n","      <td>132447.74</td>\n","      <td>-13674.21</td>\n","      <td>-9.36</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>77798.83</td>\n","      <td>71976.10</td>\n","      <td>-5822.73</td>\n","      <td>-7.48</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>191050.39</td>\n","      <td>178537.48</td>\n","      <td>-12512.91</td>\n","      <td>-6.55</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>105008.31</td>\n","      <td>116161.24</td>\n","      <td>11152.93</td>\n","      <td>10.62</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>81229.06</td>\n","      <td>67851.69</td>\n","      <td>-13377.37</td>\n","      <td>-16.47</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>97483.56</td>\n","      <td>98791.73</td>\n","      <td>1308.17</td>\n","      <td>1.34</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>110352.25</td>\n","      <td>113969.44</td>\n","      <td>3617.19</td>\n","      <td>3.28</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>166187.94</td>\n","      <td>167921.07</td>\n","      <td>1733.13</td>\n","      <td>1.04</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      y_test     y_pred        AE     RE\n","0  103282.38  103015.20   -267.18  -0.26\n","1  144259.40  132582.28 -11677.12  -8.09\n","2  146121.95  132447.74 -13674.21  -9.36\n","3   77798.83   71976.10  -5822.73  -7.48\n","4  191050.39  178537.48 -12512.91  -6.55\n","5  105008.31  116161.24  11152.93  10.62\n","6   81229.06   67851.69 -13377.37 -16.47\n","7   97483.56   98791.73   1308.17   1.34\n","8  110352.25  113969.44   3617.19   3.28\n","9  166187.94  167921.07   1733.13   1.04"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["compare = pd.DataFrame({\"y_test\": y_test, \"y_pred\": np.round(y_pred, 2) })\n","compare[\"AE\"] = compare.y_pred.sub(compare.y_test)\n","compare[\"RE\"] = compare.AE.div(compare.y_test).mul(100).round(2)\n","compare"]},{"cell_type":"markdown","metadata":{},"source":["# ALBO"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["array([[103015.2 ],\n","       [132582.28],\n","       [132447.74],\n","       [ 71976.1 ],\n","       [178537.48],\n","       [116161.24],\n","       [ 67851.69],\n","       [ 98791.73],\n","       [113969.44],\n","       [167921.07]])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["y_pred_reshaped = y_pred.reshape(len(y_pred), 1) \n","y_pred_reshaped"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["array([[103282.38],\n","       [144259.4 ],\n","       [146121.95],\n","       [ 77798.83],\n","       [191050.39],\n","       [105008.31],\n","       [ 81229.06],\n","       [ 97483.56],\n","       [110352.25],\n","       [166187.94]])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["y_test_reshaped  = y_test.reshape(len(y_test), 1) \n","y_test_reshaped "]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[103015.2  103282.38]\n"," [132582.28 144259.4 ]\n"," [132447.74 146121.95]\n"," [ 71976.1   77798.83]\n"," [178537.48 191050.39]\n"," [116161.24 105008.31]\n"," [ 67851.69  81229.06]\n"," [ 98791.73  97483.56]\n"," [113969.44 110352.25]\n"," [167921.07 166187.94]]\n"]}],"source":["print(np.concatenate((y_pred_reshaped, y_test_reshaped), axis=1))"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean Squared Error (MSE): 83502864.0326062\n","R-squared (R2): 0.93470684732822\n","Mean Absolute Error (MAE): 7514.293659643178\n"]}],"source":["from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","mae = mean_absolute_error(y_test, y_pred)\n","\n","print(\"Mean Squared Error (MSE):\", mse)\n","print(\"R-squared (R2):\", r2) # Close to one is GOOD!\n","print(\"Mean Absolute Error (MAE):\", mae)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluating for single value"]},{"cell_type":"markdown","metadata":{},"source":["### Double brackets, beacuse regressor `NEED 2D array`"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["my_values = np.array([[0,0,0, 10000, 5000, 999999]])"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["array([86976.61])"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["regressor.predict(my_values) # Profit prediction for a single given value"]},{"cell_type":"markdown","metadata":{},"source":["# `statsmodel` library nie ogarnia ze pierwszy element w Miltiple Linear Modelu to stała b0, daltego doajemy 1 na sam start \n","\n","### `Backward elemination` jest opcjonalne"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["array([[1, 0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n","       [1, 1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n","       [1, 0.0, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n","       [1, 0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n","       [1, 0.0, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n","       [1, 0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n","       [1, 1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n","       [1, 0.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n","       [1, 0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n","       [1, 1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n","       [1, 0.0, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n","       [1, 1.0, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n","       [1, 0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n","       [1, 1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n","       [1, 0.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n","       [1, 0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n","       [1, 1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n","       [1, 0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n","       [1, 0.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n","       [1, 0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n","       [1, 1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n","       [1, 0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n","       [1, 0.0, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n","       [1, 0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n","       [1, 0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n","       [1, 1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n","       [1, 0.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n","       [1, 0.0, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n","       [1, 0.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n","       [1, 0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n","       [1, 0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n","       [1, 0.0, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n","       [1, 1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n","       [1, 0.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n","       [1, 1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n","       [1, 0.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n","       [1, 0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n","       [1, 1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n","       [1, 0.0, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n","       [1, 1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n","       [1, 1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n","       [1, 0.0, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n","       [1, 1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n","       [1, 0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n","       [1, 1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n","       [1, 0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n","       [1, 0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n","       [1, 1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n","       [1, 0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n","       [1, 1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["# Building the optimal model using Backward Elimination\n","import statsmodels.api as sm\n","X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)\n","X"]},{"cell_type":"markdown","metadata":{},"source":["### `OLS = ordinary least squares` SUM (y -mean(y))^2"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.948</td>\n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.943</td>\n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   205.0</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Wed, 19 Jul 2023</td> <th>  Prob (F-statistic):</th> <td>2.90e-28</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>07:48:11</td>     <th>  Log-Likelihood:    </th> <td> -526.75</td>\n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1064.</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1073.</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 4.122e+04</td> <td> 4607.941</td> <td>    8.945</td> <td> 0.000</td> <td> 3.19e+04</td> <td> 5.05e+04</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td> 1.339e+04</td> <td> 2421.500</td> <td>    5.529</td> <td> 0.000</td> <td> 8511.111</td> <td> 1.83e+04</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td> 1.448e+04</td> <td> 2518.987</td> <td>    5.748</td> <td> 0.000</td> <td> 9405.870</td> <td> 1.96e+04</td>\n","</tr>\n","<tr>\n","  <th>x3</th>    <td> 1.335e+04</td> <td> 2459.306</td> <td>    5.428</td> <td> 0.000</td> <td> 8395.623</td> <td> 1.83e+04</td>\n","</tr>\n","<tr>\n","  <th>x4</th>    <td>    0.8609</td> <td>    0.031</td> <td>   27.665</td> <td> 0.000</td> <td>    0.798</td> <td>    0.924</td>\n","</tr>\n","<tr>\n","  <th>x5</th>    <td>   -0.0527</td> <td>    0.050</td> <td>   -1.045</td> <td> 0.301</td> <td>   -0.154</td> <td>    0.049</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>14.275</td> <th>  Durbin-Watson:     </th> <td>   1.197</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  19.260</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td>-0.953</td> <th>  Prob(JB):          </th> <td>6.57e-05</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 5.369</td> <th>  Cond. No.          </th> <td>8.35e+17</td>\n","</tr>\n","</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.55e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.948\n","Model:                            OLS   Adj. R-squared:                  0.943\n","Method:                 Least Squares   F-statistic:                     205.0\n","Date:                Wed, 19 Jul 2023   Prob (F-statistic):           2.90e-28\n","Time:                        07:48:11   Log-Likelihood:                -526.75\n","No. Observations:                  50   AIC:                             1064.\n","Df Residuals:                      45   BIC:                             1073.\n","Df Model:                           4                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       4.122e+04   4607.941      8.945      0.000    3.19e+04    5.05e+04\n","x1          1.339e+04   2421.500      5.529      0.000    8511.111    1.83e+04\n","x2          1.448e+04   2518.987      5.748      0.000    9405.870    1.96e+04\n","x3          1.335e+04   2459.306      5.428      0.000    8395.623    1.83e+04\n","x4             0.8609      0.031     27.665      0.000       0.798       0.924\n","x5            -0.0527      0.050     -1.045      0.301      -0.154       0.049\n","==============================================================================\n","Omnibus:                       14.275   Durbin-Watson:                   1.197\n","Prob(Omnibus):                  0.001   Jarque-Bera (JB):               19.260\n","Skew:                          -0.953   Prob(JB):                     6.57e-05\n","Kurtosis:                       5.369   Cond. No.                     8.35e+17\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The smallest eigenvalue is 1.55e-24. This might indicate that there are\n","strong multicollinearity problems or that the design matrix is singular.\n","\"\"\""]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n","X_opt = X_opt.astype(np.float64)\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n","regressor_OLS.summary()\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/plain":["numpy.ndarray"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Tue, 18 Jul 2023</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>11:17:34</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 5.011e+04</td> <td> 6647.870</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+04</td> <td> 6.35e+04</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td>  220.1585</td> <td> 2900.536</td> <td>    0.076</td> <td> 0.940</td> <td>-5621.821</td> <td> 6062.138</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n","</tr>\n","<tr>\n","  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131</td> <td>    0.077</td>\n","</tr>\n","<tr>\n","  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007</td> <td>    0.061</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n","</tr>\n","</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.951\n","Model:                            OLS   Adj. R-squared:                  0.946\n","Method:                 Least Squares   F-statistic:                     217.2\n","Date:                Tue, 18 Jul 2023   Prob (F-statistic):           8.49e-29\n","Time:                        11:17:34   Log-Likelihood:                -525.38\n","No. Observations:                  50   AIC:                             1061.\n","Df Residuals:                      45   BIC:                             1070.\n","Df Model:                           4                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\n","x1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\n","x2             0.8060      0.046     17.606      0.000       0.714       0.898\n","x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n","x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n","==============================================================================\n","Omnibus:                       14.758   Durbin-Watson:                   1.282\n","Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n","Skew:                          -0.948   Prob(JB):                     2.53e-05\n","Kurtosis:                       5.563   Cond. No.                     1.40e+06\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 1.4e+06. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","\"\"\""]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["X_opt = X[:, [0, 1, 3, 4, 5]]\n","X_opt = X_opt.astype(np.float64)\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n","regressor_OLS.summary()\n"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Tue, 18 Jul 2023</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>11:17:59</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n","</tr>\n","<tr>\n","  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n","</tr>\n","</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.951\n","Model:                            OLS   Adj. R-squared:                  0.948\n","Method:                 Least Squares   F-statistic:                     296.0\n","Date:                Tue, 18 Jul 2023   Prob (F-statistic):           4.53e-30\n","Time:                        11:17:59   Log-Likelihood:                -525.39\n","No. Observations:                  50   AIC:                             1059.\n","Df Residuals:                      46   BIC:                             1066.\n","Df Model:                           3                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n","x1             0.8057      0.045     17.846      0.000       0.715       0.897\n","x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n","x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n","==============================================================================\n","Omnibus:                       14.838   Durbin-Watson:                   1.282\n","Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n","Skew:                          -0.949   Prob(JB):                     2.21e-05\n","Kurtosis:                       5.586   Cond. No.                     1.40e+06\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 1.4e+06. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","\"\"\""]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["X_opt = X[:, [0, 3, 4, 5]]\n","X_opt = X_opt.astype(np.float64)\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n","regressor_OLS.summary()\n"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Tue, 18 Jul 2023</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>11:18:09</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n","</tr>\n","</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.950\n","Model:                            OLS   Adj. R-squared:                  0.948\n","Method:                 Least Squares   F-statistic:                     450.8\n","Date:                Tue, 18 Jul 2023   Prob (F-statistic):           2.16e-31\n","Time:                        11:18:09   Log-Likelihood:                -525.54\n","No. Observations:                  50   AIC:                             1057.\n","Df Residuals:                      47   BIC:                             1063.\n","Df Model:                           2                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n","x1             0.7966      0.041     19.266      0.000       0.713       0.880\n","x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n","==============================================================================\n","Omnibus:                       14.677   Durbin-Watson:                   1.257\n","Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n","Skew:                          -0.939   Prob(JB):                     2.54e-05\n","Kurtosis:                       5.575   Cond. No.                     5.32e+05\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 5.32e+05. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","\"\"\""]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["X_opt = X[:, [0, 3, 5]]\n","X_opt = X_opt.astype(np.float64)\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n","regressor_OLS.summary()\n"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Tue, 18 Jul 2023</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>11:18:12</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 4.903e+04</td> <td> 2537.897</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n","</tr>\n","</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.947\n","Model:                            OLS   Adj. R-squared:                  0.945\n","Method:                 Least Squares   F-statistic:                     849.8\n","Date:                Tue, 18 Jul 2023   Prob (F-statistic):           3.50e-32\n","Time:                        11:18:12   Log-Likelihood:                -527.44\n","No. Observations:                  50   AIC:                             1059.\n","Df Residuals:                      48   BIC:                             1063.\n","Df Model:                           1                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n","x1             0.8543      0.029     29.151      0.000       0.795       0.913\n","==============================================================================\n","Omnibus:                       13.727   Durbin-Watson:                   1.116\n","Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n","Skew:                          -0.911   Prob(JB):                     9.44e-05\n","Kurtosis:                       5.361   Cond. No.                     1.65e+05\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 1.65e+05. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","\"\"\""]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["X_opt = X[:, [0, 3]]\n","X_opt = X_opt.astype(np.float64)\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n","regressor_OLS.summary()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPhYhte6t7H4wEK4xPpDWT7","name":"Multiple Linear Regression","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"}},"nbformat":4,"nbformat_minor":0}
